## ðŸ“· SmartCamRT â€“ Real-Time Smart Camera Inference Optimizer

**SmartCamRT** is a real-time object detection and performance optimization engine designed for edge devices. It enables developers to easily deploy, monitor, and optimize AI models using various inference runtimes such as ONNX Runtime, TensorRT, TensorFlow Lite, and ExecuTorch. The system supports runtime switching, model compression, performance logging, and deployment to real edge platforms like Raspberry Pi or Android.

---

### ðŸ“¦ Project Structure
```
smartcamrt/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ onnx_runtime.py
â”‚   â”‚   â”œâ”€â”€ tensorrt.py
â”‚   â”‚   â”œâ”€â”€ tflite.py
â”‚   â”‚   â””â”€â”€ executorch.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ yolov5_utils.py
â”‚   â”‚   â””â”€â”€ transformer_utils.py
â”‚   â”œâ”€â”€ optimization/
â”‚   â”‚   â”œâ”€â”€ quantization.py
â”‚   â”‚   â”œâ”€â”€ pruning.py
â”‚   â”‚   â””â”€â”€ runtime_switcher.py
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ deploy/
â”‚   â”‚   â”œâ”€â”€ deploy_rpi.md
â”‚   â”‚   â””â”€â”€ deploy_android.md
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ sample_outputs.png
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ learn_and_replicate/
    â”œâ”€â”€ milestone_checklist.md
    â”œâ”€â”€ milestone_01_onnx_runtime/
    â”œâ”€â”€ milestone_02_tensor_rt_tflite/
    â”œâ”€â”€ milestone_03_performance_logger/
    â”œâ”€â”€ milestone_04_optimizer_logic/
    â”œâ”€â”€ milestone_05_cpp_inference/
    â”œâ”€â”€ milestone_06_sequence_models/
    â”œâ”€â”€ milestone_07_executorch/
    â”œâ”€â”€ milestone_08_compression/
    â””â”€â”€ milestone_09_edge_deployment/
```

---

### ðŸ›  Key Features and Tech Stack
- Plug-and-play runtime support: ONNX Runtime, TensorRT, TFLite, ExecuTorch
- Runtime selection and switching based on device load
- Quantization and pruning for model compression
- Performance profiling: latency, memory, CPU/GPU usage
- Deployable to Raspberry Pi and Android devices
- Python 3.12 with [`uv`](https://docs.astral.sh/uv/) for virtual env and dependency management
- PyTorch for training/export and model compression
- psutil, py3nvml for system monitoring
- pre-commit for code linting and hygiene

---

### ðŸš€ Use Cases
- Optimizing AI-powered cameras and embedded vision systems
- Benchmarking model performance across runtimes
- Researching DNN workload characteristics on edge
- Building robust real-time inference pipelines

---

### âœ… Getting Started
#### One time setup
```bash
#1. Create `.env` file from existing `.env.example` file. Update values in `.env`
cp .env.example .env

#2. Install uv if you haven't already - https://docs.astral.sh/uv/getting-started/installation/
curl -LsSf https://astral.sh/uv/install.sh | sh # macOS/Linux
powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex" # Windows

#3. Option A: Use a Python version managed by uv (recommended)
uv python install 3.12
# Setup venv with uv installed Python version
uv venv --python 3.12

#3. Option B: Use system-installed Python 3.12
brew install python@3.12
# Explicitly specify system Python version
uv venv -p $(which python3.12)

#4. Initialize pyproject.toml for dependency management
uv init
rm hello.py

#5. Install project dependencies
uv sync --extra dev

#6. Activate the environment to run commands without the `uv run` prefix
# macOS
source .venv/bin/activate
# Windows
.\.venv\Scripts\activate.ps1

#7. Install `pre-commit` git hook scripts
pre-commit install

```

#### Daily workflow
```bash
#1. Activate the environment to run commands without the `uv run` prefix
# macOS
source .venv/bin/activate
# Windows
.\.venv\Scripts\activate.ps1

#2. Run your inference e.g.
python smartcamrt/core/inference/onnx_runtime.py

#3. Re-sync dependencies after any modifications
uv sync --extra dev

```

---

### ðŸ§  Project Summary & Insights
For key results, benchmarks, and reflections on how this system was built and optimized, see the [Capstone Summary](./capstone_summary.md).

---

### ðŸ“˜ Want to Learn and Build This Yourself?
Follow [`learn_and_replicate/`](./learn_and_replicate/), which contains:
- A milestone checklist
- Modular code-by-code progression
- Replicable steps to build this full system from scratch

Perfect for those who want to learn edge AI optimization hands-on.

---

### ðŸ“ƒ License
MIT License â€“ Free to use, fork, and extend.
